# Feature: 5.1.1 Input Submission Handler

## Problem Statement

The TUI captures user input but currently only adds it to the messages list locally. The input needs to flow through to the LLM agent to get actual responses. This is the core interaction loop that makes the application functional.

## Solution Overview

Extend the TUI's `:submit` handler to:
1. Check if input is a command (starts with `/`) - defer to command handler
2. Validate that provider and model are configured
3. Clear input buffer and add user message to messages
4. Set agent status to `:processing`
5. Look up LLMAgent via Registry
6. Classify query for CoT using QueryClassifier
7. Dispatch async task to call agent
8. Broadcast status updates via PubSub

## Technical Details

### Files to Modify
- `lib/jido_code/tui.ex` - Main TUI module, update `:submit` handler

### Dependencies
- `JidoCode.AgentSupervisor` - For looking up LLMAgent by name
- `JidoCode.Agents.LLMAgent` - For chat function
- `JidoCode.Reasoning.QueryClassifier` - For CoT classification
- `Phoenix.PubSub` - For status broadcasts

### Key Design Decisions

1. **Async dispatch**: Use `Task.start/1` to avoid blocking TUI updates
2. **Agent lookup**: Look up by name `:llm_agent` via AgentSupervisor
3. **Status flow**: `:processing` on submit → `:idle` on response (handled by existing agent_response handler)
4. **Command routing**: Simple prefix check for `/` - defer full parsing to 5.2.1
5. **CoT classification**: Run QueryClassifier to inform agent (for future CoT runner integration)

## Implementation Plan

### Step 1: Add agent_name to TUI Model ✅
- [x] 1.1 Add `agent_name` field to Model (default: `:llm_agent`)
- [x] 1.2 Add `agent_name` to Model type spec

### Step 2: Update submit handler ✅
- [x] 2.1 Check if input starts with `/` - show "Commands not yet implemented"
- [x] 2.2 Validate provider and model are configured
- [x] 2.3 Show error message if unconfigured
- [x] 2.4 Clear input buffer and add user message
- [x] 2.5 Set agent_status to `:processing`

### Step 3: Dispatch to agent ✅
- [x] 3.1 Look up agent via `AgentSupervisor.lookup_agent/1`
- [x] 3.2 Handle case where agent is not found
- [x] 3.3 Classify query with QueryClassifier (for future CoT use)
- [x] 3.4 Start async Task calling `LLMAgent.chat/3`
- [x] 3.5 Agent broadcasts response via PubSub (already implemented)

### Step 4: Handle agent not found ✅
- [x] 4.1 Display error message if agent not started
- [x] 4.2 Show instructions for starting agent

### Step 5: Write tests ✅
- [x] 5.1 Test submit with unconfigured state shows error
- [x] 5.2 Test submit with command prefix shows "not yet implemented"
- [x] 5.3 Test submit with agent not found shows error
- [x] 5.4 Test agent_response sets status to idle
- [x] 5.5 Test llm_response alias works

## Success Criteria

1. ✅ User can type message and press Enter
2. ✅ If unconfigured, error message displayed
3. ✅ If configured, message sent to agent
4. ✅ Status changes to processing during request
5. ✅ Response appears in conversation when agent responds
6. ✅ All tests pass (155 tests, 0 failures)

## Current Status

**Status**: Complete
**What Works**: Full input submission flow with validation and agent dispatch
**Tests**: 155 tests, 0 failures, 1 excluded (requires API key)
**How to Run**: `mix test test/jido_code/tui_test.exs --exclude requires_api_key`
