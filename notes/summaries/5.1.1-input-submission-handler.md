# Summary: 5.1.1 Input Submission Handler

## Overview

Implemented the complete input submission flow in the TUI, connecting user input to the LLM agent. This establishes the core interaction loop: user types message → TUI validates → agent processes → response displayed.

## Files Modified

### lib/jido_code/tui.ex
Extended TUI module with input submission handling:

**New Aliases:**
- `JidoCode.Agents.LLMAgent`
- `JidoCode.AgentSupervisor`
- `JidoCode.Reasoning.QueryClassifier`

**Model Changes:**
- Added `agent_name: atom()` field (default: `:llm_agent`)

**Submit Handler Flow:**
```
update({:submit}, state)
  └─ empty? → do nothing
  └─ starts with "/" → handle_command/2 (stub)
  └─ else → handle_chat_submit/2
              └─ provider/model nil? → show_config_error/1
              └─ else → dispatch_to_agent/2
                          └─ lookup agent via AgentSupervisor
                          └─ classify query with QueryClassifier
                          └─ Task.start → LLMAgent.chat/3
                          └─ set status to :processing
```

**New Helper Functions:**
- `handle_command/2` - Stub for slash commands (shows "not yet implemented")
- `handle_chat_submit/2` - Routes to config error or agent dispatch
- `show_config_error/1` - Displays configuration required message
- `dispatch_to_agent/2` - Looks up agent, dispatches async, updates status

**Agent Response Handler:**
- Updated to set `agent_status: :idle` on response
- Added `{:llm_response, content}` alias for compatibility with LLMAgent broadcasts

## Test Coverage

### test/jido_code/tui_test.exs
Updated and added tests (155 total):

**Submit Tests (9 new):**
- Empty input does nothing
- Whitespace-only input does nothing
- Shows config error when provider is nil
- Shows config error when model is nil
- Handles command input with / prefix
- Shows agent not found error
- Sets status to processing when dispatching (requires_api_key tag)
- Trims whitespace from input

**Agent Response Tests (2 new):**
- agent_response sets status to idle
- llm_response alias works

## Message Flow

```
User types "hello" → Enter
    ↓
TUI.update({:submit}, state)
    ↓
Validate provider/model configured
    ↓
AgentSupervisor.lookup_agent(:llm_agent)
    ↓
QueryClassifier.should_use_cot?("hello")
    ↓
Task.start → LLMAgent.chat(pid, "hello")
    ↓
State: agent_status = :processing
    ↓
LLMAgent broadcasts {:llm_response, "..."} via PubSub
    ↓
TUI.update({:llm_response, content}, state)
    ↓
State: agent_status = :idle, new message added
```

## Error Handling

1. **Unconfigured state**: Shows system message asking to configure model
2. **Agent not found**: Shows error with instructions to start agent
3. **Empty input**: Silently ignored

## Dependencies

- `JidoCode.AgentSupervisor` - Registry lookup for agents
- `JidoCode.Agents.LLMAgent` - Chat function
- `JidoCode.Reasoning.QueryClassifier` - CoT classification (prepared for future use)

## Notes

- Command parsing (`/model`, `/help`, etc.) deferred to Task 5.2.1
- CoT classification result stored but not yet used (future integration)
- Agent response flow already existed; this task completes the input side
- One test requires API key and is tagged `@tag :requires_api_key`
