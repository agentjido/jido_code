defmodule JidoCode.IntegrationTest do
  @moduledoc """
  Integration tests for JidoCode end-to-end flows.

  These tests verify that different components work together correctly:
  - Supervision tree startup and process registration
  - Agent lifecycle (start/configure/stop)
  - Message flows with mocked LLM responses
  - PubSub message delivery
  - Model switching during active session
  - Tool execution flow
  - Security sandbox boundaries
  - Error handling and recovery
  """

  use ExUnit.Case, async: false

  alias JidoCode.Agents.LLMAgent
  alias JidoCode.AgentSupervisor
  alias JidoCode.TestHelpers.EnvIsolation
  alias JidoCode.Tools.{Executor, Manager, Result, Security, Tool}
  alias JidoCode.Tools.Registry, as: ToolsRegistry

  @moduletag :integration

  # ============================================================================
  # Setup
  # ============================================================================

  setup do
    Process.flag(:trap_exit, true)

    EnvIsolation.isolate(
      ["JIDO_CODE_PROVIDER", "JIDO_CODE_MODEL", "ANTHROPIC_API_KEY", "OPENAI_API_KEY"],
      [{:jido_code, :llm}]
    )

    :ok
  end

  # ============================================================================
  # 6.1.2.1 - Supervision Tree Startup and Process Registration
  # ============================================================================

  describe "supervision tree startup (6.1.2.1)" do
    test "application supervision tree starts all children" do
      # Verify main supervisor is running
      assert Process.whereis(JidoCode.Supervisor) != nil

      # Get all children
      children = Supervisor.which_children(JidoCode.Supervisor)
      child_ids = Enum.map(children, fn {id, _pid, _type, _modules} -> id end)

      # Verify all expected children are present
      assert JidoCode.Settings.Cache in child_ids
      assert Phoenix.PubSub.Supervisor in child_ids
      assert JidoCode.AgentRegistry in child_ids
      assert JidoCode.Tools.Registry in child_ids
      assert JidoCode.Tools.Manager in child_ids
      assert JidoCode.AgentSupervisor in child_ids
    end

    test "AgentRegistry accepts process registrations" do
      test_name = :"integration_test_#{:rand.uniform(100_000)}"

      # Register current process (use Elixir's Registry module)
      {:ok, _} = Elixir.Registry.register(JidoCode.AgentRegistry, test_name, %{type: :test})

      # Verify lookup works
      [{pid, value}] = Elixir.Registry.lookup(JidoCode.AgentRegistry, test_name)
      assert pid == self()
      assert value == %{type: :test}
    end

    test "PubSub allows subscribe and broadcast" do
      topic = "integration_test_#{:rand.uniform(100_000)}"

      Phoenix.PubSub.subscribe(JidoCode.PubSub, topic)
      Phoenix.PubSub.broadcast(JidoCode.PubSub, topic, {:test_msg, "hello"})

      assert_receive {:test_msg, "hello"}, 500
    end

    test "Tools.Registry is operational" do
      # Clear and verify empty state
      ToolsRegistry.clear()
      assert [] = ToolsRegistry.list()

      # Register a tool
      {:ok, tool} =
        Tool.new(%{
          name: "integration_test_tool",
          description: "Test tool",
          handler: __MODULE__,
          parameters: []
        })

      :ok = ToolsRegistry.register(tool)

      # Verify it's listed
      tools = ToolsRegistry.list()
      assert length(tools) == 1
      assert hd(tools).name == "integration_test_tool"
    end

    test "Tools.Manager is operational" do
      # Verify project_root is accessible
      {:ok, root} = Manager.project_root()
      assert is_binary(root)
      assert File.exists?(root)
    end

    test "AgentSupervisor is a DynamicSupervisor" do
      assert Process.whereis(JidoCode.AgentSupervisor) != nil
      counts = AgentSupervisor.count_children()
      assert is_map(counts)
      assert Map.has_key?(counts, :active)
    end

    test "Settings.Cache is running" do
      assert Process.whereis(JidoCode.Settings.Cache) != nil
    end

    test "multiple processes can register independently" do
      # Start multiple tasks that register themselves and verify lookup works
      tasks =
        for i <- 1..5 do
          Task.async(fn ->
            name = :"integration_process_#{i}_#{:rand.uniform(100_000)}"
            {:ok, _} = Elixir.Registry.register(JidoCode.AgentRegistry, name, %{index: i})

            # Verify the registration works while process is still alive
            [{pid, value}] = Elixir.Registry.lookup(JidoCode.AgentRegistry, name)
            {name, pid == self(), value.index == i}
          end)
        end

      # Wait for all to complete and verify they all registered successfully
      results = Task.await_many(tasks, 5000)

      for {_name, is_self, index_matches} <- results do
        assert is_self, "Process should be registered as self()"
        assert index_matches, "Registry value should have correct index"
      end

      # All 5 tasks completed successfully
      assert length(results) == 5
    end
  end

  # ============================================================================
  # 6.1.2.2 - Agent Start/Configure/Stop Lifecycle
  # ============================================================================

  describe "agent lifecycle (6.1.2.2)" do
    setup do
      System.put_env("ANTHROPIC_API_KEY", "test-key-for-integration")

      Application.put_env(:jido_code, :llm,
        provider: :anthropic,
        model: "claude-3-5-sonnet-20241022",
        temperature: 0.7,
        max_tokens: 4096
      )

      :ok
    end

    test "AgentSupervisor can start an agent" do
      agent_name = :"test_agent_#{:rand.uniform(100_000)}"

      result =
        AgentSupervisor.start_agent(%{
          name: agent_name,
          module: LLMAgent,
          args: [session_id: "integration-session"]
        })

      case result do
        {:ok, pid} ->
          assert Process.alive?(pid)

          # Verify registration
          {:ok, found_pid} = AgentSupervisor.lookup_agent(agent_name)
          assert found_pid == pid

          # Clean up
          :ok = AgentSupervisor.stop_agent(agent_name)

        {:error, _reason} ->
          # May fail if JidoAI can't fully initialize - acceptable
          :ok
      end
    end

    test "agent can be looked up by name" do
      agent_name = :"lookup_test_#{:rand.uniform(100_000)}"

      case AgentSupervisor.start_agent(%{
             name: agent_name,
             module: LLMAgent,
             args: []
           }) do
        {:ok, started_pid} ->
          {:ok, found_pid} = AgentSupervisor.lookup_agent(agent_name)
          assert started_pid == found_pid
          AgentSupervisor.stop_agent(agent_name)

        {:error, _} ->
          :ok
      end
    end

    test "lookup returns error for non-existent agent" do
      assert {:error, :not_found} = AgentSupervisor.lookup_agent(:nonexistent_agent_xyz)
    end

    test "agent can be stopped by name" do
      agent_name = :"stop_test_#{:rand.uniform(100_000)}"

      case AgentSupervisor.start_agent(%{
             name: agent_name,
             module: LLMAgent,
             args: []
           }) do
        {:ok, pid} ->
          assert Process.alive?(pid)
          :ok = AgentSupervisor.stop_agent(agent_name)

          # Wait for process to terminate
          Process.sleep(100)
          refute Process.alive?(pid)

          # Lookup should return not found
          assert {:error, :not_found} = AgentSupervisor.lookup_agent(agent_name)

        {:error, _} ->
          :ok
      end
    end

    test "agent can be stopped by pid" do
      agent_name = :"stop_pid_test_#{:rand.uniform(100_000)}"

      case AgentSupervisor.start_agent(%{
             name: agent_name,
             module: LLMAgent,
             args: []
           }) do
        {:ok, pid} ->
          :ok = AgentSupervisor.stop_agent(pid)
          Process.sleep(100)
          refute Process.alive?(pid)

        {:error, _} ->
          :ok
      end
    end

    test "agent start rejects invalid specs" do
      # Missing name
      assert {:error, msg} = AgentSupervisor.start_agent(%{module: LLMAgent})
      assert is_binary(msg)

      # Missing module
      assert {:error, msg} = AgentSupervisor.start_agent(%{name: :test})
      assert is_binary(msg)
    end
  end

  # ============================================================================
  # 6.1.2.3 - Full Message Flow with Mocked LLM Responses
  # ============================================================================

  describe "message flow (6.1.2.3)" do
    setup do
      System.put_env("ANTHROPIC_API_KEY", "test-key")

      Application.put_env(:jido_code, :llm,
        provider: :anthropic,
        model: "claude-3-5-sonnet-20241022"
      )

      :ok
    end

    test "message validation rejects empty messages" do
      {:error, {:empty_message, msg}} = LLMAgent.chat(self(), "")
      assert String.contains?(msg, "empty")
    end

    test "message validation rejects oversized messages" do
      long_msg = String.duplicate("x", 10_001)
      {:error, {:message_too_long, msg}} = LLMAgent.chat(self(), long_msg)
      assert String.contains?(msg, "10000")
    end

    test "message validation accepts valid messages" do
      # This would normally make an LLM call, so we just verify validation passes
      # by checking it doesn't return a validation error

      case LLMAgent.start_link(session_id: "msg-flow-test") do
        {:ok, pid} ->
          # Try to send - will likely timeout or fail without real API
          result = LLMAgent.chat(pid, "Test message", timeout: 100)

          case result do
            {:error, {:empty_message, _}} -> flunk("Should not reject valid message")
            {:error, {:message_too_long, _}} -> flunk("Should not reject short message")
            # Any other result is acceptable
            _ -> :ok
          end

          GenServer.stop(pid, :normal, 1000)

        {:error, _} ->
          :ok
      end
    end

    test "stream validation also applies" do
      {:error, {:empty_message, _}} = LLMAgent.chat_stream(self(), "")
    end
  end

  # ============================================================================
  # 6.1.2.4 - PubSub Message Delivery Between Agent and TUI
  # ============================================================================

  describe "PubSub delivery (6.1.2.4)" do
    setup do
      System.put_env("ANTHROPIC_API_KEY", "test-key")

      Application.put_env(:jido_code, :llm,
        provider: :anthropic,
        model: "claude-3-5-sonnet-20241022"
      )

      :ok
    end

    test "agent session provides topic for subscription" do
      session_id = "pubsub-test-#{:rand.uniform(100_000)}"

      case LLMAgent.start_link(session_id: session_id) do
        {:ok, pid} ->
          {:ok, ^session_id, topic} = LLMAgent.get_session_info(pid)
          assert topic == "tui.events.#{session_id}"
          GenServer.stop(pid, :normal, 1000)

        {:error, _} ->
          :ok
      end
    end

    test "topic_for_session builds correct format" do
      assert LLMAgent.topic_for_session("my-session") == "tui.events.my-session"
    end

    test "config_changed broadcasts to session topic" do
      session_id = "config-change-test-#{:rand.uniform(100_000)}"

      System.put_env("OPENAI_API_KEY", "test-openai-key")

      case LLMAgent.start_link(session_id: session_id) do
        {:ok, pid} ->
          # Subscribe to session topic
          {:ok, ^session_id, topic} = LLMAgent.get_session_info(pid)
          Phoenix.PubSub.subscribe(JidoCode.PubSub, topic)

          # Try to reconfigure
          case LLMAgent.configure(pid, provider: :openai, model: "gpt-4o") do
            :ok ->
              assert_receive {:config_changed, _old, _new}, 1000

            {:error, _} ->
              # May fail if AI agent can't start - acceptable
              :ok
          end

          GenServer.stop(pid, :normal, 1000)

        {:error, _} ->
          :ok
      end
    end

    test "tool execution broadcasts to PubSub" do
      ToolsRegistry.clear()

      {:ok, tool} =
        Tool.new(%{
          name: "pubsub_broadcast_test",
          description: "Test",
          handler: __MODULE__.TestHandler,
          parameters: [%{name: "value", type: :string, description: "Value", required: true}]
        })

      :ok = ToolsRegistry.register(tool)

      # Subscribe
      Phoenix.PubSub.subscribe(JidoCode.PubSub, "tui.events")

      # Execute
      tool_call = %{id: "call_1", name: "pubsub_broadcast_test", arguments: %{"value" => "test"}}
      {:ok, _result} = Executor.execute(tool_call)

      # Should receive events (with nil session_id since none provided)
      assert_receive {:tool_call, "pubsub_broadcast_test", %{"value" => "test"}, "call_1", nil}, 1000
      assert_receive {:tool_result, %Result{}, nil}, 1000
    end

    test "session-specific topics isolate messages" do
      session_a = "session_a_#{:rand.uniform(100_000)}"
      session_b = "session_b_#{:rand.uniform(100_000)}"

      # Subscribe to session A only
      Phoenix.PubSub.subscribe(JidoCode.PubSub, "tui.events.#{session_a}")

      ToolsRegistry.clear()

      {:ok, tool} =
        Tool.new(%{
          name: "isolation_test",
          description: "Test",
          handler: __MODULE__.TestHandler,
          parameters: []
        })

      :ok = ToolsRegistry.register(tool)

      # Execute on session B
      tool_call = %{id: "call_b", name: "isolation_test", arguments: %{}}
      {:ok, _} = Executor.execute(tool_call, session_id: session_b)

      # Should NOT receive on session A (session_id in 5th position)
      refute_receive {:tool_call, "isolation_test", _, _, _}, 200
    end
  end

  # ============================================================================
  # 6.1.2.5 - Model Switching During Active Session
  # ============================================================================

  describe "model switching (6.1.2.5)" do
    setup do
      System.put_env("ANTHROPIC_API_KEY", "test-key")
      System.put_env("OPENAI_API_KEY", "test-openai-key")

      Application.put_env(:jido_code, :llm,
        provider: :anthropic,
        model: "claude-3-5-sonnet-20241022",
        temperature: 0.7,
        max_tokens: 4096
      )

      :ok
    end

    test "configure updates agent config" do
      case LLMAgent.start_link() do
        {:ok, pid} ->
          initial_config = LLMAgent.get_config(pid)
          assert initial_config.provider == :anthropic

          # Try updating temperature (same provider, should work)
          case LLMAgent.configure(pid, temperature: 0.5) do
            :ok ->
              new_config = LLMAgent.get_config(pid)
              assert new_config.temperature == 0.5

            {:error, _} ->
              :ok
          end

          GenServer.stop(pid, :normal, 1000)

        {:error, _} ->
          :ok
      end
    end

    test "configure rejects invalid provider" do
      case LLMAgent.start_link() do
        {:ok, pid} ->
          {:error, msg} = LLMAgent.configure(pid, provider: :invalid_xyz)
          assert is_binary(msg)
          assert String.contains?(msg, "not found") or String.contains?(msg, "invalid")

          # Config should be unchanged
          config = LLMAgent.get_config(pid)
          assert config.provider == :anthropic

          GenServer.stop(pid, :normal, 1000)

        {:error, _} ->
          :ok
      end
    end

    test "configure rejects invalid model" do
      case LLMAgent.start_link() do
        {:ok, pid} ->
          {:error, msg} = LLMAgent.configure(pid, model: "nonexistent-model")
          assert is_binary(msg)

          config = LLMAgent.get_config(pid)
          assert config.model == "claude-3-5-sonnet-20241022"

          GenServer.stop(pid, :normal, 1000)

        {:error, _} ->
          :ok
      end
    end

    test "configure rejects missing API key for new provider" do
      # Remove OpenAI key
      System.delete_env("OPENAI_API_KEY")

      case LLMAgent.start_link() do
        {:ok, pid} ->
          {:error, msg} = LLMAgent.configure(pid, provider: :openai, model: "gpt-4o")
          assert String.contains?(msg, "API key") or String.contains?(msg, "OPENAI")

          GenServer.stop(pid, :normal, 1000)

        {:error, _} ->
          :ok
      end
    end

    test "configure returns ok when config unchanged" do
      case LLMAgent.start_link() do
        {:ok, pid} ->
          config = LLMAgent.get_config(pid)

          result =
            LLMAgent.configure(pid,
              provider: config.provider,
              model: config.model,
              temperature: config.temperature,
              max_tokens: config.max_tokens
            )

          assert result == :ok

          GenServer.stop(pid, :normal, 1000)

        {:error, _} ->
          :ok
      end
    end
  end

  # ============================================================================
  # 6.1.2.6 - Tool Execution Flow
  # ============================================================================

  describe "tool execution flow (6.1.2.6)" do
    setup do
      ToolsRegistry.clear()

      {:ok, tool} =
        Tool.new(%{
          name: "flow_test_tool",
          description: "Test tool for flow",
          handler: __MODULE__.TestHandler,
          parameters: [
            %{name: "input", type: :string, description: "Input", required: true}
          ]
        })

      :ok = ToolsRegistry.register(tool)

      :ok
    end

    test "tool registration and lookup works" do
      {:ok, tool} = ToolsRegistry.get("flow_test_tool")
      assert tool.name == "flow_test_tool"
      assert tool.handler == __MODULE__.TestHandler
    end

    test "tool call parsing extracts arguments" do
      llm_response = %{
        "tool_calls" => [
          %{
            "id" => "call_flow_1",
            "type" => "function",
            "function" => %{
              "name" => "flow_test_tool",
              "arguments" => ~s({"input": "hello"})
            }
          }
        ]
      }

      {:ok, [tool_call]} = Executor.parse_tool_calls(llm_response)
      assert tool_call.id == "call_flow_1"
      assert tool_call.name == "flow_test_tool"
      assert tool_call.arguments == %{"input" => "hello"}
    end

    test "tool execution calls handler" do
      tool_call = %{id: "call_exec_1", name: "flow_test_tool", arguments: %{"input" => "world"}}
      {:ok, result} = Executor.execute(tool_call)

      assert result.status == :ok
      assert result.tool_call_id == "call_exec_1"
      assert result.content == "Processed: world"
    end

    test "tool results can be formatted as LLM messages" do
      tool_call = %{id: "call_fmt_1", name: "flow_test_tool", arguments: %{"input" => "format"}}
      {:ok, result} = Executor.execute(tool_call)

      [message] = Result.to_llm_messages([result])
      assert message.role == "tool"
      assert message.tool_call_id == "call_fmt_1"
      assert message.content == "Processed: format"
    end

    test "batch execution processes multiple tool calls" do
      tool_calls = [
        %{id: "batch_1", name: "flow_test_tool", arguments: %{"input" => "a"}},
        %{id: "batch_2", name: "flow_test_tool", arguments: %{"input" => "b"}}
      ]

      {:ok, results} = Executor.execute_batch(tool_calls)
      assert length(results) == 2
      assert Enum.all?(results, &(&1.status == :ok))
    end
  end

  # ============================================================================
  # 6.1.2.7 - Tool Sandbox Security
  # ============================================================================

  describe "tool sandbox security (6.1.2.7)" do
    test "path traversal is blocked" do
      {:error, :path_escapes_boundary} =
        Security.validate_path("../../../etc/passwd", File.cwd!(), log_violations: false)
    end

    test "absolute paths outside project are blocked" do
      {:error, :path_outside_boundary} =
        Security.validate_path("/etc/passwd", File.cwd!(), log_violations: false)
    end

    test "valid paths within project are allowed" do
      {:ok, resolved} =
        Security.validate_path("lib/jido_code.ex", File.cwd!(), log_violations: false)

      assert String.starts_with?(resolved, File.cwd!())
    end

    test "Lua sandbox blocks os.execute" do
      {:error, reason} = Manager.execute("return os.execute('echo hello')")
      assert reason =~ "nil" or reason =~ "attempt to call"
    end

    test "Lua sandbox blocks io.popen" do
      {:error, reason} = Manager.execute("return io.popen('ls')")
      assert reason =~ "nil" or reason =~ "attempt to call"
    end

    test "Lua sandbox blocks require" do
      {:error, reason} = Manager.execute("return require('os')")
      assert reason =~ "nil" or reason =~ "attempt to call"
    end
  end

  # ============================================================================
  # 6.1.2.8 - Graceful Error Handling and Recovery
  # ============================================================================

  describe "error handling (6.1.2.8)" do
    setup do
      ToolsRegistry.clear()

      {:ok, error_tool} =
        Tool.new(%{
          name: "error_test_tool",
          description: "Tool that errors",
          handler: __MODULE__.ErrorHandler,
          parameters: []
        })

      {:ok, slow_tool} =
        Tool.new(%{
          name: "slow_test_tool",
          description: "Slow tool",
          handler: __MODULE__.SlowHandler,
          parameters: [%{name: "delay", type: :integer, description: "Delay", required: true}]
        })

      :ok = ToolsRegistry.register(error_tool)
      :ok = ToolsRegistry.register(slow_tool)

      :ok
    end

    test "tool execution handles handler errors gracefully" do
      tool_call = %{id: "err_1", name: "error_test_tool", arguments: %{}}
      {:ok, result} = Executor.execute(tool_call)

      assert result.status == :error
      assert result.content =~ "intentional error"
    end

    test "tool execution handles timeout" do
      tool_call = %{id: "timeout_1", name: "slow_test_tool", arguments: %{"delay" => 500}}
      {:ok, result} = Executor.execute(tool_call, timeout: 50)

      assert result.status == :timeout
      assert result.content =~ "timed out"
    end

    test "non-existent tool returns error result" do
      tool_call = %{id: "noexist_1", name: "nonexistent_xyz", arguments: %{}}
      {:ok, result} = Executor.execute(tool_call)

      assert result.status == :error
      assert result.content =~ "not found"
    end

    test "invalid arguments return error result" do
      # missing required
      tool_call = %{id: "invalid_1", name: "slow_test_tool", arguments: %{}}
      {:ok, result} = Executor.execute(tool_call)

      assert result.status == :error
      assert result.content =~ "missing required parameter"
    end

    test "Lua execution errors are contained" do
      {:error, _reason} = Manager.execute("this is not valid lua")
      # The Manager should still be operational
      {:ok, result} = Manager.execute("return 42")
      assert result == 42 or result == 42.0
    end
  end

  # ============================================================================
  # Test Handlers
  # ============================================================================

  defmodule TestHandler do
    def execute(%{"value" => value}, _context), do: {:ok, "Value: #{value}"}
    def execute(%{"input" => input}, _context), do: {:ok, "Processed: #{input}"}
    def execute(_args, _context), do: {:ok, "Executed"}
  end

  defmodule ErrorHandler do
    def execute(_args, _context), do: {:error, "intentional error"}
  end

  defmodule SlowHandler do
    def execute(%{"delay" => delay}, _context) do
      Process.sleep(delay)
      {:ok, "completed"}
    end
  end
end
